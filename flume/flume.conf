flume1.sources = kafka-source-1
flume1.channels = hdfs-channel-1
flume1.sinks = hdfs-sink-1

flume1.sources.kafka-source-1.type = org.apache.flume.source.kafka.KafkaSource
flume1.sources.kafka-source-1.zookeeperConnect = 10.129.0.7:2181
flume1.sources.kafka-source-1.topic = anime-events
flume1.sources.kafka-source-1.batchSize = 25000
flume1.sources.kafka-source-1.channels = hdfs-channel-1
flume1.sources.kafka-source-1.kafka.consumer.group.id = my-flume

# Use for set start offset is 0 for first set consumer group id
flume1.sources.kafka-source-1.kafka.consumer.auto.offset.reset = earliest

flume1.channels.hdfs-channel-1.type = memory

flume1.sinks.hdfs-sink-1.channel = hdfs-channel-1
flume1.sinks.hdfs-sink-1.type = hdfs
flume1.sinks.hdfs-sink-1.hdfs.writeFormat = Text
flume1.sinks.hdfs-sink-1.hdfs.fileType = DataStream
flume1.sinks.hdfs-sink-1.hdfs.filePrefix = anime-events
flume1.sinks.hdfs-sink-1.hdfs.useLocalTimeStamp = true
flume1.sinks.hdfs-sink-1.hdfs.rollCount = 100
flume1.sinks.hdfs-sink-1.hdfs.rollSize = 0

# Used three / for fix error:
# - java.lang.IllegalArgumentException: java.net.UnknownHostException:
flume1.sinks.hdfs-sink-1.hdfs.path = hdfs:///user/data/kafka/%{topic}/%y-%m-%d

# For fix error:
# - Hit max consecutive under-replication rotations (30);
# - will not continue rolling files under this path due to under-replication
flume1.sinks.hdfs-sink-1.hdfs.minBlockReplicas = 1

# For fix error:
# - org.apache.flume.ChannelFullException: Space for commit to queue couldn't be acquired.
# - Sinks are likely not keeping up with sources, or the buffer size is too tight
flume1.channels.hdfs-channel-1.keep-alive = 60
flume1.channels.hdfs-channel-1.capacity = 1000000
flume1.channels.hdfs-channel-1.transactionCapacity = 50000
